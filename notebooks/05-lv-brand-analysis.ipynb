{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac8568-f4b6-4a32-8482-621b561beb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b233a9e-f8c3-4f77-8d6d-08a58e120499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..')) # or the path to your source code\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5353709-6dbd-4837-8da7-699d471b030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1994e2a-4f30-4d56-ba29-bb7203ce1992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_project.config import PROCESSED_DATA_DIR, INTERIM_DATA_DIR, FIGURES_DIR\n",
    "from nlp_project.sentiment_analysis import json_sentences_and_features_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0bab1-935e-483a-ac37-e63e30896e50",
   "metadata": {},
   "source": [
    "# BRAND ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d2677-c7dd-499f-b5ce-2f0c039c3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(PROCESSED_DATA_DIR / 'preprocessed_dataset.csv', sep=';')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56032d-9a74-4c50-9b88-d5a0e93d73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rinomina la colonna reviewTime in year\n",
    "dataset = dataset.rename(columns={'reviewTime': 'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ae83c-cde0-4d41-adf9-465a7c4b8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_top5_brands = dataset[dataset['brand'].isin(['Samsung', 'Motorola', 'Apple', 'BlackBerry', 'LG'])]\n",
    "dataset_top5_brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a672791-fc7c-4d7a-963a-a77aabe43eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Raggruppiamo le recensioni per anno e contiamo quante ce ne sono per ogni anno\n",
    "reviews_per_year = dataset_top5_brands.groupby('year').size().reset_index(name='count')\n",
    "# Creiamo il grafico a barre con Plotly\n",
    "fig = px.bar(reviews_per_year, x='year', y='count', title='Numero di Recensioni per Anno', \n",
    "             labels={'year':'Anno', 'count':'Numero di Recensioni'}, \n",
    "             text='count')\n",
    "\n",
    "# Mostriamo il grafico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55aca7-dc84-458e-8cd0-ff380f49b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_top5_brands[dataset_top5_brands['year'] >= 2013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6edfd8-beb5-4918-b136-c25ae702e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per contare le occorrenze delle features in una review\n",
    "def count_features_in_review(review, features):\n",
    "    feature_count = {}\n",
    "    for feature in features:\n",
    "        # Trova il numero di occorrenze della feature nel testo della review (case insensitive)\n",
    "        feature_count[feature] = len(re.findall(r'\\b' + re.escape(feature) + r'\\b', review.lower()))\n",
    "    return feature_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d483437-5464-4aa4-be35-49675c03f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(PROCESSED_DATA_DIR / 'ontology_filtered.csv', sep=';').iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb782e-73bf-483d-9d2a-7eb90d881c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applica la funzione alle review per contare le features\n",
    "df['feature_counts'] = df['reviewText'].apply(lambda x: count_features_in_review(x, features))\n",
    "\n",
    "# Trasforma il dizionario di conteggi in colonne individuali per ogni feature\n",
    "feature_df = pd.DataFrame(df['feature_counts'].tolist(), index=df.index)\n",
    "\n",
    "# Aggiungi le colonne delle features al dataframe originale\n",
    "df = pd.concat([df, feature_df], axis=1)\n",
    "\n",
    "#Raggeùruppa per brand e sommare le occorrenze delle features\n",
    "brand_feature_freq = df.groupby('brand')[features].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18c543-2339-4cf2-9089-14b23a511358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brand_feature_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df54a4-91a5-41a7-83f7-1052365b1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_features = {}\n",
    "k = 5\n",
    "# Itera su ciascun brand e crea un plot con le 5 features più frequenti\n",
    "for brand in brand_feature_freq.index:\n",
    "    # Ordina le features per frequenza e prendi le 5 più frequenti\n",
    "    top_10_features = brand_feature_freq.loc[brand].nlargest(k)\n",
    "    top_features[brand] = top_10_features.index.to_list()\n",
    "    # Creazione del grafico\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.barplot(x=top_10_features.values, y=top_10_features.index, palette=\"Blues_d\")\n",
    "    \n",
    "    # Aggiungi titolo e label\n",
    "    plt.title(f'Top {k} Features for {brand}', fontsize=16)\n",
    "    plt.xlabel('Frequency', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    \n",
    "    # Mostra il grafico\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / f'{brand}_most_cited_features.png', format='png')  # Salva con il nome del brand\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e7199-fa13-4d8f-b10c-d8dbba27bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f4d707-0372-4507-9b8a-54ca0fe1555e",
   "metadata": {},
   "source": [
    "## come è cambiato nel tempo il sentiment nei confronti di queste features, per ciascun brand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0d1df-9ee6-42e0-9945-1dae67c0a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dizionario per salvare i DataFrame per ciascun brand e anno\n",
    "brand_year_dfs = {}\n",
    "\n",
    "for brand in df['brand'].unique():\n",
    "    for year in df['year'].unique():\n",
    "        # Filtra il dataframe per il brand e l'anno corrente\n",
    "        filtered_df = df[(df['brand'] == brand) & (df['year'] == year)]\n",
    "        \n",
    "        # Salva il dataframe in un dizionario con chiave come (brand, year)\n",
    "        brand_year_dfs[(brand, year)] = filtered_df\n",
    "\n",
    "        # Opzionale: puoi stampare la dimensione del dataframe o una preview\n",
    "        #print(f\"DataFrame per {brand} nel {year}:\")\n",
    "        #print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0f281-0d38-4479-805e-6e011816e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brand_year_dfs[('Apple', 2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43acbee8-aa24-407d-a4ba-c246e69b047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "sent_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle') #sentence_tokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f1e39-92c0-42c4-92e0-0bed1ae82aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "def calculate_features_scores_brand_year(brand_year_dfs, filtered_features): \n",
    "    for (brand, year), df in brand_year_dfs.items(): \n",
    "        print(f\"Calcolo delle features per {brand} nel {year}\")\n",
    "        json_sentences_and_features_scores(df,filtered_feautes, lemmatizer, stop_words, afinn, sent_tokenizer, save_path=f'brand_analysis/bert_features_scores_{brand}_{year}.json')\n",
    "        # Applicare la funzione a ogni recensione e raggruppare per 'asin'\n",
    "        #df['preprocessed_sentences'] = df['reviewText'].progress_apply(preprocess_analyze_sentences, args=('bert',))\n",
    "        \n",
    "        # Raggruppare per 'asin' e combinare le sentences\n",
    "        #grouped = df.groupby('asin')['preprocessed_sentences'].progress_apply(list).reset_index()\n",
    "        #grouped['preprocessed_sentences'] = grouped['preprocessed_sentences'].progress_apply(combine_sentences)\n",
    "        #grouped['features'] = grouped['preprocessed_sentences'].progress_apply(lambda x: extract_features(x, filtered_features['value']))\n",
    "        \n",
    "        #result = grouped.to_dict(orient='records')\n",
    "        #Salva il risultato in un file JSON\n",
    "        #with open(f'data/bert_features_scores_{brand}_{year}.json', 'w') as f:\n",
    "        #  json.dump(result, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e379a-f4fd-4654-9c84-293c3b38eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate_features_scores_brand_year(brand_year_dfs, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef22be-4170-4edf-b25f-e6769440181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Definisci la directory che contiene i file JSON\n",
    "json_directory = PROCESSED_DATA_DIR / 'brands_analysis/'\n",
    "\n",
    "# Dizionario per salvare le medie delle features per ciascun brand e anno\n",
    "brand_year_averages = {}\n",
    "\n",
    "# Itera su ciascun file JSON nella directory\n",
    "for filename in os.listdir(json_directory):\n",
    "    if filename.endswith(\".json\"):\n",
    "        # Estrai brand e anno dal nome del file (es: Apple_2018.json)\n",
    "        brand, year = filename.replace(\".json\", \"\").split('_')\n",
    "        \n",
    "        # Carica il file JSON\n",
    "        with open(os.path.join(json_directory, filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Dizionario per accumulare i punteggi delle features\n",
    "        feature_scores = defaultdict(list)\n",
    "        \n",
    "        # Itera su ciascun prodotto nel file JSON\n",
    "        for product in data:\n",
    "            # Prendi il dizionario delle features e i relativi punteggi\n",
    "            features = product.get('features', {})\n",
    "            \n",
    "            # Accumula i punteggi per ciascuna feature\n",
    "            for feature, score in features.items():\n",
    "                feature_scores[feature].append(score)\n",
    "        \n",
    "        # Ora possiamo calcolare la media per ciascuna feature\n",
    "        feature_means = {feature: sum(scores) / len(scores) for feature, scores in feature_scores.items()}\n",
    "        \n",
    "        # Salva le medie nel dizionario brand_year_averages\n",
    "        brand_year_averages[(brand, year)] = feature_means\n",
    "\n",
    "        # Opzionale: stampa le medie per il brand e anno corrente\n",
    "        #print(f\"Medie delle features per {brand} nel {year}:\")\n",
    "        #print(feature_means)\n",
    "\n",
    "# Converti il dizionario brand_year_averages in un DataFrame per una visualizzazione più comoda\n",
    "df_averages = pd.DataFrame.from_dict(brand_year_averages, orient='index')\n",
    "\n",
    "# Mostra il DataFrame finale\n",
    "#print(df_averages)\n",
    "\n",
    "# Opzionale: salva il DataFrame su disco in formato CSV\n",
    "#df_averages.to_csv('feature_averages_per_brand_year.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f225bd4-fe0d-458e-97c2-8c20fed58df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7b838-f6f1-487e-9825-db6df797ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_averages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9612389-0268-41f5-aeee-e2ae93feafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_averages = df_averages.reset_index(drop=False)\n",
    "\n",
    "# Lista dei brand disponibili nel DataFrame\n",
    "brands = df_averages['level_0'].unique()  # level_0 contiene i brand\n",
    "\n",
    "# Itera su ciascun brand\n",
    "for brand in brands:\n",
    "    # Filtra il DataFrame per il brand corrente\n",
    "    df_brand = df_averages[df_averages['level_0'] == brand]\n",
    "    \n",
    "    # Filtra il DataFrame per includere solo le colonne battery e screen\n",
    "    df_brand_filtered = df_brand[['level_1'] + ['battery', 'screen']]  # 'level_1' contiene l'anno\n",
    "\n",
    "    # Rinominare le colonne se necessario\n",
    "    df_brand_filtered.rename(columns={'level_1': 'year'}, inplace=True)\n",
    "\n",
    "    # Converti la colonna 'year' in formato numerico\n",
    "    df_brand_filtered['year'] = df_brand_filtered['year'].astype(int)\n",
    "\n",
    "    # Raggruppa per anno per ottenere la media delle features per ogni anno (se ci fossero dati duplicati)\n",
    "    df_grouped_brand = df_brand_filtered.groupby('year').mean()\n",
    "    df_cumulative = df_grouped_brand.expanding().mean()\n",
    "\n",
    "    # Crea il grafico di linee per ogni feature per il brand corrente\n",
    "    plt.figure(figsize=(6,4))\n",
    "\n",
    "    for feature in ['battery', 'screen']:\n",
    "        plt.plot(df_cumulative.index, df_cumulative[feature], marker='o', label=feature)\n",
    "\n",
    "    # Aggiungi titolo e etichette\n",
    "    plt.title(f\"trend screen e battery per {brand} (2013-2018)\")\n",
    "    plt.xlabel(\"Anno\")\n",
    "    plt.ylabel(\"Media cumulata dei Punteggi delle Features\")\n",
    "    plt.legend(title=\"Features\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Mostra il grafico\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGURES_DIR / f'{brand}_features_trend.png', format='png')  # Salva con il nome del brand\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0aa12a-b487-4afa-89a6-151a01f371c2",
   "metadata": {},
   "source": [
    "1. Le feature 'screen'e 'battery' per il brand BlackBerry hanno mostrato un graduale miglioramento nella percezione dei consumatori, come indicato dall'aumento costante del sentiment cumulativo dal 2013 al 2018. Questo riflette probabilmente i miglioramenti tecnologici e l'importanza crescente dello schermo e della batteria negli smartphone BlackBerry.\n",
    "\n",
    "2. mentre per gli altri brand si nota un trend decrescente nella percezione dei consumatori per queste due features, il che può indicare il fatto che siano necessari dei miglioramenti."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
