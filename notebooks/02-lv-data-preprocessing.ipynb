{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..')) # or the path to your source code\n",
    "sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_project.config import INTERIM_DATA_DIR, PROCESSED_DATA_DIR\n",
    "from nlp_project.plots import sb_bar_plot,plotly_ex_barplot \n",
    "from nlp_project.dataset import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(PROCESSED_DATA_DIR / 'cell_phones_reviews.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ESPLORIAMO IL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimozione righe con valori null per prezzo e reviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(subset=['price', 'reviewText'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex per il formato corretto dei prezzi\n",
    "regex = re.compile(r'^\\$\\d+\\.\\d+$')\n",
    "\n",
    "# Filtriamo i dati applicando la regex alla colonna 'price'\n",
    "dataset = dataset[dataset['price'].apply(lambda x: bool(regex.match(x)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rimuoviamo il simbolo del dollaro dalla colonna 'prezzi'\n",
    "dataset['price'] = dataset['price'].str.replace('$', '', regex=False).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quanti cellulari diversi sono rimasti dopo aver rimosso le reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['asin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count_per_product = dataset.groupby('asin').size().reset_index(name='counts').sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count_per_product = reviews_count_per_product.merge(\n",
    "    dataset[['asin', 'title']].drop_duplicates(),\n",
    "    on='asin',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count_per_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_100_reviews = reviews_count_per_product[reviews_count_per_product['counts'] < 100]['asin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_ex_barplot(data=reviews_count_per_product[:50], x='title', y='counts', color='counts', height=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count_per_product = reviews_count_per_product[reviews_count_per_product['counts'] >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count_per_product.to_csv(INTERIM_DATA_DIR / 'reviews_count_per_product.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_count_per_product[reviews_count_per_product[\"title\"] ==\n",
    "\"Samsung Galaxy S3 Mini GT-i8190 GSM Unlocked International Version White - NO WARRANTY\"][\"asin\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reviews relative ai prodotti aventi meno di 100 reviews, che vengono rimosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[dataset['asin'].isin(less_100_reviews)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['asin'].isin(less_100_reviews)]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# Per risultati pi√π consistenti con langdetect\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "# Funzione per rilevare la lingua\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Rileva la lingua di ogni recensione\n",
    "dataset['language'] = dataset['reviewText'].apply(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['language'].isin(['es', 'pt'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# from afinn import Afinn\n",
    "\n",
    "# afinn = Afinn()\n",
    "# def preprocess(df, column):\n",
    "#     preprocessed_text = []\n",
    "#     tagged_text = []\n",
    "#     for row in tqdm(df[column], total = len(df[column])):\n",
    "#         afinn_scores = []\n",
    "#         text_cleaned = re.sub(r'[^\\w\\s]', '', row) #cleaning\n",
    "#         words = nltk.word_tokenize(text_cleaned) #tokenization\n",
    "#         words = [w.lower() for w in words]\n",
    "#         preprocessed_words = [lemmatizer.lemmatize(w) for w in words if not w in stop_words] #stopwords removal and lemmatization\n",
    "#         preprocessed_text.append(' '.join(preprocessed_words))\n",
    "#         tagged_words = nltk.pos_tag(preprocessed_words, tagset='universal') #POS-tagging\n",
    "#         #afinn scores\n",
    "#         for word, tag in tagged_words:\n",
    "#             score = afinn.score(word)\n",
    "#             afinn_scores.append((word, tag, score))\n",
    "#         tagged_text.append(afinn_scores)\n",
    "\n",
    "#     return preprocessed_text, tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from afinn import Afinn\n",
    "\n",
    "afinn = Afinn()\n",
    "def preprocess(df, column):\n",
    "    preprocessed_text = []\n",
    "    tagged_text = []\n",
    "    for row in tqdm(df[column], total = len(df[column])):\n",
    "        afinn_scores = []\n",
    "        text_cleaned = re.sub(r'[^\\w\\s]', '', row) #cleaning: remove all character that aren't whitespaces or alphanumeric\n",
    "        words = nltk.word_tokenize(text_cleaned) #tokenization\n",
    "        words = [w.lower() for w in words] #lower casing\n",
    "        tagged_words = nltk.pos_tag(words, tagset='universal') #POS-tagging\n",
    "        preprocessed_words = [(lemmatizer.lemmatize(w), tag) for w, tag in tagged_words if not w in stop_words] #stopwords removal and lemmatization\n",
    "        preprocessed_text.append(' '.join([w for w, tag in preprocessed_words]))\n",
    "        #afinn scores\n",
    "        for word, tag in preprocessed_words:\n",
    "            score = afinn.score(word)\n",
    "            afinn_scores.append((word, tag, score))\n",
    "        tagged_text.append(afinn_scores)\n",
    "\n",
    "    return preprocessed_text, tagged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['preprocessed_text'], dataset['tagged_text'] = preprocess(dataset, 'reviewText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['reviewText'].iloc[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['feature', 'language'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(PROCESSED_DATA_DIR / 'preprocessed_dataset.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_phones_brand_counts = dataset['brand'].value_counts().reset_index()\n",
    "cell_phones_brand_counts.columns = ['brand', 'count'] \n",
    "sb_bar_plot(x = cell_phones_brand_counts['count'],\n",
    "            y = cell_phones_brand_counts['brand'],\n",
    "            orient='h',\n",
    "            title='top 10 brand', \n",
    "            xlabel='Count', \n",
    "            ylabel='Brand')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_phones_brand_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
